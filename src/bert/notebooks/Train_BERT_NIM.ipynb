{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35aa5ee2",
   "metadata": {},
   "source": [
    "# Train the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a3a394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import BertWordPieceTokenizer, ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# paths = [str(x) for x in Path(\".\").glob(\"text_split/*.txt\")]\n",
    "path = os.path.realpath(\"../../data/nim_fen.txt\")\n",
    "\n",
    "tokenizer_folder = os.path.realpath(\"./bert-nim\")\n",
    "\n",
    "MAX_LEN = 128\n",
    "\n",
    "vocab_size = 16384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a067bd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{'[MOVESEP]': 0}\n",
      "\n",
      "\n",
      "\n",
      "{'9': 16, 'b2': 58, '##E': 42, 'c0': 56, 'b6': 69, 'b10': 82, ']': 26, 'c4': 63, '7': 14, 'A': 17, 'a1': 52, '##9': 30, '2': 9, '[MOVESEP]': 0, '##0': 35, 'a': 27, '##6': 36, 'c10': 80, 'b3': 62, 'a9': 81, '6': 13, 'b9': 79, 'a10': 83, 'a4': 65, 'MOVE': 49, '##1': 33, 'c9': 77, 'c2': 57, '[CLS]': 2, 'E': 19, '0': 7, 'M': 20, 'b4': 64, 'c3': 61, '##5': 32, 'c5': 67, 'P': 22, 'c7': 72, '##VE': 46, '[PAD]': 0, '4': 11, 'c1': 51, '[UNK]': 1, 'a3': 60, 'a5': 68, '##4': 31, '5': 12, '3': 10, '##S': 43, '##P': 44, 'b0': 55, 'c': 29, '8': 15, 'a8': 78, '##7': 39, '[MASK]': 4, '##2': 38, 'c8': 75, 'a2': 59, '##SEP': 48, 'S': 23, '##3': 34, 'MOVESEP': 50, 'b5': 66, 'b7': 73, 'a0': 54, '1': 8, 'O': 21, '/': 6, 'b': 28, '[': 25, '##O': 40, '##EP': 47, 'b8': 76, '[SEP]': 3, 'MO': 45, 'b1': 53, 'B': 18, '##V': 41, 'a7': 74, 'a6': 71, '##8': 37, 'V': 24, 'c6': 70}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a tokenizer\n",
    "tokenizer = BertWordPieceTokenizer(lowercase=False, clean_text=True)\n",
    "print(tokenizer.add_special_tokens([\"[MOVESEP]\"]))\n",
    "\n",
    "print(tokenizer.get_vocab())\n",
    "\n",
    "# Customize training\n",
    "tokenizer.train(files=path, vocab_size=vocab_size, min_frequency=1,\n",
    "                show_progress=True,\n",
    "                special_tokens= ['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]', '[MOVESEP]'])\n",
    "\n",
    "print(tokenizer.get_vocab())\n",
    "#Save the Tokenizer to disk\n",
    "#tokenizer.save(tokenizer_folder + \"/vocab.json\")\n",
    "#tokenizer.save_model(tokenizer_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea871f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/michael/Workspace/nlp-chess/src/bert/bert-nim/vocab.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_model(tokenizer_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d27dd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a1', '/', 'b9', '/', 'c9', '[MOVESEP]', 'a2', '[MASK]']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "BertWordPieceTokenizer(os.path.join(tokenizer_folder, \"vocab.txt\"))\n",
    "# Prepare the tokenizer\n",
    "# tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "#     (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "#     (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    "# )\n",
    "tokenizer.enable_truncation(max_length=128)\n",
    "# Test the tokenizer\n",
    "tokenizer.encode(\"a1/b9/c9 [MOVESEP] a2\")\n",
    "# Show the tokens created\n",
    "tokenizer.encode(\"a1/b9/c9 [MOVESEP] a2 [MASK]\").tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8964f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num parameters:  56115712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Workspace/nlp-chess/env/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1646: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig\n",
    "from transformers import BertForMaskedLM\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Set a configuration for our RoBERTa model\n",
    "config = BertConfig(\n",
    "    vocab_size=vocab_size,\n",
    "    max_position_embeddings=514,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1,\n",
    ")\n",
    "# Initialize the model from a configuration without pretrained weights\n",
    "model = BertForMaskedLM(config=config)\n",
    "print('Num parameters: ',model.num_parameters())\n",
    "\n",
    "# Create the tokenizer from a trained one\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_folder + \"/vocab.txt\", max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5161cf5",
   "metadata": {},
   "source": [
    "# Build the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceb44923",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-cc76579b29d52e13\n",
      "Reusing dataset text (/home/michael/.cache/huggingface/datasets/text/default-cc76579b29d52e13/0.0.0/d86c40dad297bdddf277b406c6a59f0250b5318c400bf23d420a31aff88c84c4)\n",
      "Loading cached shuffled indices for dataset at /home/michael/.cache/huggingface/datasets/text/default-cc76579b29d52e13/0.0.0/d86c40dad297bdddf277b406c6a59f0250b5318c400bf23d420a31aff88c84c4/cache-ea496f9ced065590.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import set_caching_enabled\n",
    "raw_datasets = load_dataset('text', data_files=path,\n",
    "                            split='train')\n",
    "\n",
    "#cut size in half\n",
    "raw_datasets = raw_datasets.shuffle(seed=42)\n",
    "\n",
    "#raw_datasets = raw_datasets.select(range(10000))\n",
    "raw_datasets = raw_datasets.train_test_split()\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding='max_length', truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True, keep_in_memory=True, num_proc=20, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8836037-2a43-4d96-9297-944ea84d5d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'input_ids': [2,\n",
       "  68,\n",
       "  6,\n",
       "  66,\n",
       "  6,\n",
       "  56,\n",
       "  28,\n",
       "  25,\n",
       "  1,\n",
       "  26,\n",
       "  60,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e9fdc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'input_ids': [2, 68, 6, 66, 6, 56, 28, 25, 1, 26, 60, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "grouping complete\n"
     ]
    }
   ],
   "source": [
    "# tokenized_datasets = raw_datasets\n",
    "#     with open(\"dataset-tokenized.obj\", 'wb') as f:\n",
    "#         pickle.dump(tokenized_datasets, f)\n",
    "\n",
    "# block_size = tokenizer.model_max_length\n",
    "\n",
    "block_size = 128\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    #result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "print(tokenized_datasets[\"train\"][1])\n",
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=20,\n",
    "    keep_in_memory=True\n",
    ")\n",
    "\n",
    "print(\"grouping complete\")\n",
    "\n",
    "small_train_dataset = lm_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "# small_train_dataset[\"labels\"] = small_train_dataset[\"input_ids\"]\n",
    "small_eval_dataset = lm_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n",
    "# small_eval_dataset[\"labels\"] = small_eval_dataset[\"input_ids\"]\n",
    "full_train_dataset = lm_datasets[\"train\"]\n",
    "full_eval_dataset = lm_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c5541c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15065"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "717e2ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Workspace/nlp-chess/env/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 15065\n",
      "  Num Epochs = 200\n",
      "  Instantaneous batch size per device = 425\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 425\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7200' max='7200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7200/7200 1:47:35, Epoch 200/200]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.971263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.274453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.035670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.929868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.894555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.887162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.861466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.813817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.802635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.779824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.735692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.698939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.702429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.124200</td>\n",
       "      <td>0.681297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.124200</td>\n",
       "      <td>0.688943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.124200</td>\n",
       "      <td>0.687252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.124200</td>\n",
       "      <td>0.651455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.124200</td>\n",
       "      <td>0.647866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.124200</td>\n",
       "      <td>0.633661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.124200</td>\n",
       "      <td>0.628372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.124200</td>\n",
       "      <td>0.633559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.124200</td>\n",
       "      <td>0.633948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.124200</td>\n",
       "      <td>0.633981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.124200</td>\n",
       "      <td>0.603228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.124200</td>\n",
       "      <td>0.602912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.124200</td>\n",
       "      <td>0.610255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.124200</td>\n",
       "      <td>0.595130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.556761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.560367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.550279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.528117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.533596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.533031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.530662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.514608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.508108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.504922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.487847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.497091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.486245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.483275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.484888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.494587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.466186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.460850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.474237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.472384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.479096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.454839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.460261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.456658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.443567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.448615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.445952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.430803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.491300</td>\n",
       "      <td>0.444692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.491300</td>\n",
       "      <td>0.453025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.491300</td>\n",
       "      <td>0.448765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.491300</td>\n",
       "      <td>0.438237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.491300</td>\n",
       "      <td>0.439843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.491300</td>\n",
       "      <td>0.447531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.491300</td>\n",
       "      <td>0.437152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.491300</td>\n",
       "      <td>0.443080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.491300</td>\n",
       "      <td>0.438554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.491300</td>\n",
       "      <td>0.422032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.491300</td>\n",
       "      <td>0.437330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.491300</td>\n",
       "      <td>0.438419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.491300</td>\n",
       "      <td>0.428007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.491300</td>\n",
       "      <td>0.422573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>0.419313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>0.426289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>0.419794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>0.447894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>0.444390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>0.442793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>0.402830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>0.432429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>0.440587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>0.436724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>0.441954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>0.432216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>0.436008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>0.463264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.439858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.404353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.404680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.401417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.400989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.419555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.404686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.404334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.433181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.420120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.416849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.413716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.408669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.397375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.428500</td>\n",
       "      <td>0.420908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.428500</td>\n",
       "      <td>0.404526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.428500</td>\n",
       "      <td>0.388773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.428500</td>\n",
       "      <td>0.423313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.428500</td>\n",
       "      <td>0.403409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.428500</td>\n",
       "      <td>0.417358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.428500</td>\n",
       "      <td>0.402849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.428500</td>\n",
       "      <td>0.416327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.428500</td>\n",
       "      <td>0.400947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.428500</td>\n",
       "      <td>0.393360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.428500</td>\n",
       "      <td>0.401635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.428500</td>\n",
       "      <td>0.408642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.428500</td>\n",
       "      <td>0.411774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.428500</td>\n",
       "      <td>0.415124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.378211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.387387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.385740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.394651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.411179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.382475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.401254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.413747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.382886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.398422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.406419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.402917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.389243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.371454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.401487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.392089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.388992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.391239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.404605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.389084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.386777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.367524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.385762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.396564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.367677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.359114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.425572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.371395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.393733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.370812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.387299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.374518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.377701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.370699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.368808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.367047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.375853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.369331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.376995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.363939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.373660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.394676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.374648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.356414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.368736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.382921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.362036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.354683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.404016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.383774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.379590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.374503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.392179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.363129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.386882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.387051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.374542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.385876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.363020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.371099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.418739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.368574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.390741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.388088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.391123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.383464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.366414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.380425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.364116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.386707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.386806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.385287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.349811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.379651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.374393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.370568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.372027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.380840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.389368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.388677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.377881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.396150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.357979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.381100</td>\n",
       "      <td>0.367953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0.381100</td>\n",
       "      <td>0.342683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0.381100</td>\n",
       "      <td>0.366302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.381100</td>\n",
       "      <td>0.394590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>0.381100</td>\n",
       "      <td>0.383984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.381100</td>\n",
       "      <td>0.381585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output-nim/checkpoint-500\n",
      "Configuration saved in ./output-nim/checkpoint-500/config.json\n",
      "Model weights saved in ./output-nim/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output-nim/checkpoint-1000\n",
      "Configuration saved in ./output-nim/checkpoint-1000/config.json\n",
      "Model weights saved in ./output-nim/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output-nim/checkpoint-1500\n",
      "Configuration saved in ./output-nim/checkpoint-1500/config.json\n",
      "Model weights saved in ./output-nim/checkpoint-1500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output-nim/checkpoint-2000\n",
      "Configuration saved in ./output-nim/checkpoint-2000/config.json\n",
      "Model weights saved in ./output-nim/checkpoint-2000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output-nim/checkpoint-2500\n",
      "Configuration saved in ./output-nim/checkpoint-2500/config.json\n",
      "Model weights saved in ./output-nim/checkpoint-2500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output-nim/checkpoint-3000\n",
      "Configuration saved in ./output-nim/checkpoint-3000/config.json\n",
      "Model weights saved in ./output-nim/checkpoint-3000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output-nim/checkpoint-3500\n",
      "Configuration saved in ./output-nim/checkpoint-3500/config.json\n",
      "Model weights saved in ./output-nim/checkpoint-3500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output-nim/checkpoint-4000\n",
      "Configuration saved in ./output-nim/checkpoint-4000/config.json\n",
      "Model weights saved in ./output-nim/checkpoint-4000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output-nim/checkpoint-4500\n",
      "Configuration saved in ./output-nim/checkpoint-4500/config.json\n",
      "Model weights saved in ./output-nim/checkpoint-4500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output-nim/checkpoint-5000\n",
      "Configuration saved in ./output-nim/checkpoint-5000/config.json\n",
      "Model weights saved in ./output-nim/checkpoint-5000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output-nim/checkpoint-5500\n",
      "Configuration saved in ./output-nim/checkpoint-5500/config.json\n",
      "Model weights saved in ./output-nim/checkpoint-5500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output-nim/checkpoint-6000\n",
      "Configuration saved in ./output-nim/checkpoint-6000/config.json\n",
      "Model weights saved in ./output-nim/checkpoint-6000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output-nim/checkpoint-6500\n",
      "Configuration saved in ./output-nim/checkpoint-6500/config.json\n",
      "Model weights saved in ./output-nim/checkpoint-6500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output-nim/checkpoint-7000\n",
      "Configuration saved in ./output-nim/checkpoint-7000/config.json\n",
      "Model weights saved in ./output-nim/checkpoint-7000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5022\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7200, training_loss=0.4911639075809055, metrics={'train_runtime': 6455.9312, 'train_samples_per_second': 466.703, 'train_steps_per_second': 1.115, 'total_flos': 9.981897572352e+16, 'train_loss': 0.4911639075809055, 'epoch': 200.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=425,\n",
    "    output_dir='./output-nim', \n",
    "    num_train_epochs=200,\n",
    "    evaluation_strategy=\"epoch\")\n",
    "\n",
    "from transformers import Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm_probability=0.15,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, args=training_args, train_dataset=full_train_dataset, eval_dataset=full_eval_dataset, data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2f3903b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to trained_model2\n",
      "Configuration saved in trained_model2/config.json\n",
      "Model weights saved in trained_model2/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"trained_model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeaf8e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BertHarmon import BertHarmon\n",
    "from stockfish import Stockfish\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os\n",
    "\n",
    "REPO_DIR = os.path.realpath(\"../../\")\n",
    "\n",
    "STOCKFISH_BINARY_PATH = os.path.join(REPO_DIR,\n",
    "                                     \"stockfish_build\",\n",
    "                                     \"stockfish\",\n",
    "                                     \"src\",\n",
    "                                     \"stockfish\")\n",
    "\n",
    "class EvaluateValidMoves:\n",
    "    \n",
    "    def __init__(self, model_checkpoint, tokenizer_checkpoint, num_games=100, max_moves=3):\n",
    "        self.model = BertHarmon(model_checkpoint, tokenizer_checkpoint)\n",
    "        \n",
    "        self.num_games = num_games\n",
    "        self.max_moves = max_moves\n",
    "        \n",
    "    def test(self):\n",
    "        valid_moves_per_game = []\n",
    "        for game_num in tqdm(range(self.num_games)):\n",
    "            # Setup the game\n",
    "            self.stockfish = Stockfish(path=STOCKFISH_BINARY_PATH,\n",
    "                                       parameters={\"Threads\": 1,\n",
    "                                                   \"Minimum Thinking Time\": 50,\n",
    "                                                   \"Use NNUE\": True})\n",
    "\n",
    "            self.stockfish.set_elo_rating(3900)\n",
    "            self.stockfish.set_depth(1)\n",
    "            \n",
    "            # run the game\n",
    "            num_valid_moves = 0\n",
    "            moves = []\n",
    "            for i in range(self.max_moves):\n",
    "                \n",
    "                # stockfish move\n",
    "                \n",
    "                move = self.stockfish.get_best_move()\n",
    "                moves.append(move)\n",
    "                \n",
    "                self.stockfish.make_moves_from_current_position([move])\n",
    "                \n",
    "                # bert move\n",
    "                \n",
    "                move = self.model.make_move(self.stockfish.get_fen_position())[0][\"token_str\"].replace(\" \", \"\")\n",
    "                \n",
    "                if self.stockfish.is_move_correct(move):\n",
    "                    moves.append(move)\n",
    "                    num_valid_moves += 1\n",
    "                    self.stockfish.make_moves_from_current_position([move])\n",
    "                else:\n",
    "                    move = self.stockfish.get_best_move()\n",
    "                    if move is None:\n",
    "                        num_valid_moves += self.max_moves - i\n",
    "                        break\n",
    "                    moves.append(move)\n",
    "                    self.stockfish.make_moves_from_current_position([move])\n",
    "            #print(moves)       \n",
    "            #with open(f\"games/{game_num}.txt\", \"w\") as f:\n",
    "            #    f.write(\"\\n\".join(moves))\n",
    "            valid_moves_per_game.append(num_valid_moves)\n",
    "            \n",
    "        return valid_moves_per_game\n",
    "                \n",
    "                \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e8ee7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Workspace/nlp-chess/env/lib/python3.7/site-packages/ipykernel_launcher.py:24: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3de9cbc857441c29798d6059c304777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f854042207b142eab37708545c9685e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a241693b94495695d4314a5f453ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e308ab1575244bea8d2714f46a6b1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afffc4f43df8484f889f8169dacb795b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d83fd583d54bdca519de93b0b0d543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c648420f5d466eb9ba573369990c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164121babf664e9bb3ed771f09248a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8220de6781348eda1575c75587b01a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ad5e2b4bcb4ba5b655417a43b8cfeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003b858cc2254de680231dc5c478d22e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd265e463d6048ea9903eff9d3c381a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eed6bf31f4742ffb72aeb3ad11b6b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39b3f67595c414a917d6cb39ce9eb2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2befe0954147bb9824c03c7d8eefb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bfc368f4fb492c965bef293566558a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4abebe5aef744de9a46e480352b172b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d76dc877f314cfc913ba1d8f08a7507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53d698ee2e24494b4d7b57b3370f6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3480763fdc504e0d8650ea135819ed01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137a993db3cd478db9c3cb4f2216dca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2817c80140437ca816c668b00ac4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c495b84556bd4547894a2702a6dde55a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ced87214bea446dbf0e7ffd1fb440cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2107d718d04014baf6fdf9c21312a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db84bf1f422041d4b5340be0c3094ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d7774ad94f4cb3ba50ec10c0ff6c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f6933bf0224f598885ac78c74fdfe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a10fea2a5644d10825d2007165b57e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f0fb567a1942fcb5375a4e0571ca50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ef8fa41b3e4ec6bb06edbd30b16415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f3bb628e1f41bc9b5d73ef24b1181c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb6883abca549acb2e092d27c1a6401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0ad5643dfd49c7b7194cb72faec958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c95992d2bff4439837953bc22b145f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "895c106d62184f6982f013c976d1cedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd12d073c9054d92b6cc0ca24e9cd001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b651614e6d0041ada35106db4ac34d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582d99ff2925478c8f904430f38b699d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "benchmark = []\n",
    "for i in range(1, 40):\n",
    "    print(i)\n",
    "    res = EvaluateValidMoves(\"trained_model2\", \"./bert-harmon/vocab.txt\", max_moves=i).test()\n",
    "    benchmark.append(np.average(res) / i)\n",
    "\n",
    "\n",
    "#Evaluator = EvaluateValidMoves(\"trained_model2\", \"./bert-harmon/vocab.txt\", max_moves=moves)\n",
    "#num_valid_moves = Evaluator.test()\n",
    "\n",
    "\n",
    "\n",
    "#print(np.average(num_valid_moves))\n",
    "#print(np.average(num_valid_moves) / moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4babf19e-b437-4828-89be-5db4162002fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.998,\n",
       " 0.9916666666666667,\n",
       " 0.9800000000000001,\n",
       " 0.9775,\n",
       " 0.9755555555555555,\n",
       " 0.968,\n",
       " 0.94,\n",
       " 0.9533333333333333,\n",
       " 0.9107692307692308,\n",
       " 0.915,\n",
       " 0.9046666666666667,\n",
       " 0.885625,\n",
       " 0.8994117647058824,\n",
       " 0.8594444444444445,\n",
       " 0.863157894736842,\n",
       " 0.8545,\n",
       " 0.839047619047619,\n",
       " 0.8286363636363636,\n",
       " 0.8160869565217391,\n",
       " 0.7866666666666666,\n",
       " 0.7951999999999999,\n",
       " 0.7623076923076924,\n",
       " 0.7762962962962964,\n",
       " 0.7839285714285714,\n",
       " 0.7644827586206897,\n",
       " 0.7566666666666666,\n",
       " 0.7519354838709676,\n",
       " 0.75375,\n",
       " 0.7196969696969697,\n",
       " 0.7185294117647059,\n",
       " 0.7282857142857142,\n",
       " 0.7388888888888889,\n",
       " 0.7148648648648649,\n",
       " 0.7363157894736843,\n",
       " 0.7138461538461538]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0ba04b3-fab3-4ee5-bd19-4c7e312a8e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'BERT Accuracy')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(benchmark)\n",
    "plt.xlabel(\"Game Length\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"BERT Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c8174e-7cec-4a5b-b93c-0fa798167551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
